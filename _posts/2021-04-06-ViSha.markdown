---
layout: default
title:  "Welcome to ViSha!"
date:   2021-04-06 17:50:00
categories: main
---

## Introduction for ViSha
**ViSha** is a short name for "Video shadow detection dataset". ViSha includes 120 videos with diverse content, varying length, and object-level annotations. More than half videos are from 5 widely-used video tracking benchmarks (i.e., OTB[1], VOT[2], LaSOT[3], TC-128[4], and NfS[5]). The remaining 59 videos are self-captured with different hand-held cameras, over different scenes, at varying times. The frame rate is adjusted to 30 fps for all video sequences.  
Eventually, **ViSha** contains 120 video sequences, with a totally of 11,685 frames and 390 seconds duration. The longest video contains 103 frames and the shortest contains 11 frames.

## Quikly know ViSha

<img src="https://github.com/eraserNut/eraserNut.github.io/blob/main/_posts/video1_compass_gif2.gif?raw=true">

## Form of ViSha
To provide guidelines for future works, we randomly split the dataset into training and testing sets with a ratio of 5:7. The 50 training set and 70 testing set can be downloaded *above this page*.

If you download ViSha and unzip each file, you can find the dataset structure as follows:

    ▾ <train>/
        ▾ images/
            ▾ baby_cat/
                00000001.jpg
                ...
            ▾ baby_wave1/
                00000001.jpg
                ...
            ...
        ▾ labels/
            ▾ baby_cat/
                00000001.png
                ...
            ▾ baby_wave1/
                00000001.png
                ...
            ...
    ▾ <test>/
        ...

<!-- <img src="https://github.com/eraserNut/eraserNut.github.io/blob/main/_posts/folder_structure.png?raw=true" height="500"> -->


## Statistics of ViSha
**ViSha include many shadow attributes:**

<img src="https://github.com/eraserNut/eraserNut.github.io/blob/main/_posts/visha_sta.png?raw=true" width="730">


**Visualization of the statistics of ViSha.** (a) Shadow categories. (b) Ratio distribution of the shadows. (c) Mutual dependencies among shadow categories in (a).

<img src="https://github.com/eraserNut/eraserNut.github.io/blob/main/_posts/visha_figure.png?raw=true" width="700">

## Citation
**If you utilize ViSha in your work, please cite our paper as follows**  
```
@inproceedings{chen21TVSD,   
&nbsp;&nbsp;&nbsp;&nbsp;  author = {Chen, Zhihao and Wan, Liang and Zhu, Lei and Shen, Jia and Fu, Huazhu and Liu,    
&nbsp;&nbsp;&nbsp;&nbsp;  Wennan and Qin, Jing},    
&nbsp;&nbsp;&nbsp;&nbsp;  title = {Triple-cooperative Video Shadow Detection},    
&nbsp;&nbsp;&nbsp;&nbsp;  booktitle = {CVPR},    
&nbsp;&nbsp;&nbsp;&nbsp;  year  = {2021}    
}
```  
Paper arXiv link: https://arxiv.org/abs/2103.06533

## Reference
<small>[1]Y. Wu, J. Lim, and M. H. Yang. Object tracking benchmark. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37(9):1834–1848, 2015.  
[2]M. Kristan, J. Matas, A. Leonardis, T. Vojir, R. Pﬂugfelder, G. Fernandez, G. Nebehay, F. Porikli, and L. Cehovin. A novel performance evaluation methodology for single-target trackers. IEEE Transactions on Pattern Analysis and Machine Intelligence, 38(11):2137–2155, 2016.  
[3]H. Fan, H. Ling, L. Lin, F. Yang, P. Chu, G. Deng, S. Yu, H. Bai, Y. Xu, and C. Liao. Lasot: A high-quality benchmark for large-scale single object tracking. In CVPR, pages 5374–5383, 2019.  
[4]P. Liang, E. Blasch, and H. Ling. Encoding color information for visual tracking: Algorithms and benchmark. IEEE Transactions on Image Processing, 24(12):5630–5644, 2015.  
[5]Hamed Kiani Galoogahi, Ashton Fagg, Chen Huang, Deva Ramanan, and Simon Lucey. Need for speed: A benchmark for higher frame rate object tracking. In ICCV, pages 1134–1143, 2017.</small>
